<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Categories:Algorithm | Free Mind]]></title>
  <link href="http://shengmingzhiqing.com/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://shengmingzhiqing.com/"/>
  <updated>2016-07-10T16:34:48+08:00</updated>
  <id>http://shengmingzhiqing.com/</id>
  <author>
    <name><![CDATA[Jie Huang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Greedy Algorithm]]></title>
    <link href="http://shengmingzhiqing.com/blog/greedy-algorithm.html/"/>
    <updated>2016-07-06T22:44:20+08:00</updated>
    <id>http://shengmingzhiqing.com/blog/greedy-algorithm</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section">1. 活动选择问题</a>    <ul>
      <li><a href="#section-1">动态规划</a></li>
      <li><a href="#section-2">贪心选择</a></li>
    </ul>
  </li>
  <li><a href="#section-3">2. 算法实现</a></li>
  <li><a href="#section-4">3. 算法原理</a>    <ul>
      <li><a href="#section-5">贪心选择性质</a></li>
      <li><a href="#section-6">最优子结构</a></li>
    </ul>
  </li>
  <li><a href="#section-7">4. 贪心对动态规划</a></li>
</ul>

<p>贪心算法在每一步都做出当时看起来最佳的选择。它总是做出局部最优的选择，寄希望这样的选择能导致全局最优解。</p>

<!--more-->

<h2 id="section">1. 活动选择问题</h2>

<p>目标是选出一个最大的相互兼容的活动集合。</p>

<h3 id="section-1">动态规划</h3>
<p>设 $s_{ij}$ 表示在活动 $a_i$ 结束之后开始，且在 $a_j$ 开始之前结束的那些活动的集合。如果 $c[i,j]$ 表示集合的最优解大小，则,</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

c[i,j] =\left\{\begin{matrix}
0 & if(s_{ij}\neq \phi ) \\ 
\underset{a_k\in s_{ij}}{max} \{c[i,k] + c[k,j] + 1\} & if(s_{ij}= \phi )
\end{matrix}\right.
 %]]&gt;</script>

<p>因为面临这样的选择：$s_{ij}$ 中的最优解包含哪个活动 $a_k$。所以动态规划算法需要考查它所有的活动。</p>

<h3 id="section-2">贪心选择</h3>
<p>每次选择 $s$ 中最早结束的活动。</p>

<h2 id="section-3">2. 算法实现</h2>

<p>贪心算法通常都是自顶向下的设计：做出一个选择，然后求解剩下的那个子问题，而不是自底向上地求解出很多子问题，然后再做出选择。此外也可以很容易地将算法转换为迭代的形式。</p>

<h2 id="section-4">3. 算法原理</h2>

<p>贪心算法的两个关键要素：贪心选择性质和最优子结构</p>

<h3 id="section-5">贪心选择性质</h3>
<p>可以通过做出局部最优的选择来构造全局最优解。这也是贪心算法与动态规划的不同之处，在动态规划中每个步骤都有多种选择，选择通常依赖于子问题的解，例如：</p>

<script type="math/tex; mode=display">
c[i,j]=\underset{i\leq k\leq j}{max}\{c[i,k]+c[k,j]+1\}
</script>

<p>当然，我们必须证明每个步骤做出贪心选择能生成全局最优解。首先考查某个子问题的最优解，然后用贪心选择替换某个其他选择来修改此解，从而得到一个相似的最优解（子问题的最优解）。</p>

<h3 id="section-6">最优子结构</h3>
<p>如果一个问题的最优解包含了其他子问题的最优解，则称此问题具有最优子结构性质。</p>

<h2 id="section-7">4. 贪心对动态规划</h2>

<p>两种算法都利用了最优子结构性质，很相似。但是两者有细微差别。比如<code>0-1 背包问题</code>和<code>分数背包问题</code>。<code>分数背包问题</code>可以用贪心算法，但是<code>0-1 背包问题</code>不能用贪心算法。因为对<code>0-1 背包问题</code>使用贪心算法时不能保证背包装满，而空闲的空间降低了单位重量的价值。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dynamic Programming]]></title>
    <link href="http://shengmingzhiqing.com/blog/dynamic-programming.html/"/>
    <updated>2016-07-06T21:02:53+08:00</updated>
    <id>http://shengmingzhiqing.com/blog/dynamic-programming</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section">动态规划算法四步骤：</a></li>
  <li><a href="#section-1">动态规划原理</a>    <ul>
      <li><a href="#section-2">最优子结构</a></li>
      <li><a href="#section-3">重叠子问题</a></li>
    </ul>
  </li>
  <li><a href="#section-4">动态规划两种等价的实现方法</a>    <ul>
      <li><a href="#top-down-with-memoization">带备忘的自顶向下 (top-down with memoization)</a></li>
      <li><a href="#bottom-up-method">自底向上 (bottom-up method)</a></li>
    </ul>
  </li>
  <li><a href="#section-5">应用</a>    <ul>
      <li><a href="#section-6">1. 石子合并问题</a></li>
    </ul>
  </li>
</ul>

<p>动态规划应用于子问题重叠问题，分治算法会反复求解那些公共子问题，而动态规划算法会对子问题只求解一次，将其解保存在一个表格中，避免不必要的计算。</p>

<!--more-->

<h2 id="section">动态规划算法四步骤：</h2>
<ol>
  <li>刻画一个最优解的结构特征 (最优子结构)</li>
  <li>递归地定义最优解的值</li>
  <li>计算最优解的值，通常采用自底向上的方法</li>
  <li>利用计算出的信息构造一个最优解</li>
</ol>

<h2 id="section-1">动态规划原理</h2>
<p>适用动态规划方法求解的最优问题应该具备两个要素：<strong>最优子结构</strong>和<strong>子问题重叠</strong></p>

<h3 id="section-2">最优子结构</h3>
<p>如果原问题的最优解包含其子问题的最优解，就称此问题具有最优子结构。</p>

<p>发掘最优子结构性质的过程中，遵循如下模式：</p>

<ol>
  <li>证明问题最优解的第一个组成部分是做出一个选择，做出这次选择会产生一个或多个待解决的子问题。</li>
  <li>在第一步选择中，假定已经知道哪种选择会得到最优解。你现在并不关心这种选择具体是如何得到的，只是假定已经知道这种选择。</li>
  <li>给定可获得最优解的选择后，你确定这次选择会产生哪些子问题，以及如何最好地刻画子问题空间。</li>
  <li>利用“剪切-粘贴” (cut-paste) 技术证明：作为构成原问题最优解的组成部分，每一个子问题的最优解就是它本身的最优解。</li>
</ol>

<p>我们可以用子问题的个数和每个子问题需要考察多少种选择这两个因素的乘积来粗略分析动态规划算法的运行时间。</p>

<p>在动态规划方法中，通常自底向上地使用最优子结构，也就是说，首先求得子问题的最优解，然后在其中进行选择来求原问题的最优解。</p>

<p>注：动态规划子问题无关：同一个原问题的一个子问题的解不影响另一个子问题的解。放过来说，就是要避免求解一个子问题时用到了某些资源，导致这些资源在求解其他子问题时不可用。</p>

<h3 id="section-3">重叠子问题</h3>
<p>如果递归算法反复求解相同的子问题，称最优化问题具有重叠子问题 (overlapping subproblems) 性质。</p>

<h2 id="section-4">动态规划两种等价的实现方法</h2>

<h3 id="top-down-with-memoization">带备忘的自顶向下 (top-down with memoization)</h3>
<p>仍按自然递归形式编写过程，但过程中会保存每个子问题的解。当需要一个子问题的解时，过程首先检查是否已经保存过此解。如果是则直接返回保存的结果；否则按通常方式计算这个子问题，并保存结果。</p>

<h3 id="bottom-up-method">自底向上 (bottom-up method)</h3>
<p>将子问题按规模排序，按由小自大顺序进行求解。当求解某个子问题时，它所依赖的那些更小的子问题都已经求解完毕，结果已经保存。</p>

<p>两种算法具有相同的渐进运行时间，但自底向上算法会比自顶向下备忘算法快(相差一个常量系数)，因为自底向上算法没有递归调用的开销。</p>

<h2 id="section-5">应用</h2>

<h3 id="section-6">1. 石子合并问题</h3>
<p>（1）有 N 堆石子，现要将石子有序的合并成一堆，规定如下：每次只能移动<strong>任意</strong>的 2 堆石子合并，合并花费为新合成的一堆石子的数量。求将这 N 堆石子合并成一堆的总花费最小（或最大）。</p>

<p>分析：当然这种情况是最简单的情况，合并的是任意两堆，直接贪心即可，每次选择最小的两堆合并。本问题实际上就是哈夫曼的变形。</p>

<p>（2） 有 N 堆石子，现要将石子有序的合并成一堆，规定如下：每次只能移动<strong>相邻</strong>的 2 堆石子合并，合并花费为新合成的一堆石子的数量。求将这 N 堆石子合并成一堆的总花费最小（或最大）。</p>

<p>分析：我们熟悉矩阵连乘，知道矩阵连乘也是每次合并相邻的两个矩阵，那么石子合并可以用矩阵连乘的方式来解决。</p>

<p>设 dp[i][j] 表示第 i 到第 j 堆石子合并的最优值，sum[i][j] 表示第 i 到第 j 堆石子的总数量。那么就有状态转移公式：</p>

<script type="math/tex; mode=display">dp[i][j]=\left\{\begin{matrix}
0, if(i =j) \\ 
min(dp[i][k]+dp[i][k+1]+sum[i][j]), other
\end{matrix}\right.</script>

<p>（3） 问题(2)的是在石子排列是直线情况下的解法，现在考虑把石子改为环形排列。因为石子绕成一个环，不是一条直线，所以 dp[i][j] 的含义应为从第 i 堆开始，合并 j 堆石子能得到的最优值。则易得状态转移方程为:</p>

<script type="math/tex; mode=display">dp[i][j] = min(dp[i][k]+dp[(i+k)\%n][j-k]+sum[i][j])</script>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sorting]]></title>
    <link href="http://shengmingzhiqing.com/blog/sorting.html/"/>
    <updated>2016-07-06T20:38:32+08:00</updated>
    <id>http://shengmingzhiqing.com/blog/sorting</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#section">排序的稳定性</a></li>
  <li><a href="#bubble-sort">冒泡排序 (Bubble Sort)</a></li>
  <li><a href="#selection-sort">选择排序 (Selection Sort)</a></li>
  <li><a href="#insertion-sort">插入排序 (Insertion Sort)</a></li>
  <li><a href="#shell-sort">希尔排序 (Shell Sort)</a></li>
  <li><a href="#heap-sort">堆排序 (Heap Sort)</a></li>
  <li><a href="#merge-sort">归并排序 (Merge Sort)</a></li>
  <li><a href="#quick-sort">快速排序 (Quick Sort)</a></li>
  <li><a href="#bucket-sort">桶排序 (Bucket Sort)</a></li>
  <li><a href="#counting-sort">计数排序 (Counting Sort)</a></li>
</ul>

<p>希尔排序相当于插入排序，同属于插入排序类；堆排序相当于选择排序的升级，同属于选择类排序；而快速排序是冒泡排序的升级，同属于交换排序类。</p>

<!--more-->

<h3 id="section">排序的稳定性</h3>
<p>假设 $k_i = k_j$，且在排序前 $i&lt;j$。如果排序后仍然  $i&lt;j$，则称所用排序算法是稳定的。否则排序算法不稳定。</p>

<hr />

<h3 id="bubble-sort">冒泡排序 (Bubble Sort)</h3>
<p>思想：两两比较相邻记录的数值，如果反序则交换，直到没有反序的记录为止。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/2016-07-06-sorting-bubble-sort.png' width='512' height='512' title=''><span class='caption-text'></span></span></p>

<p>复杂度：时间复杂度为 $O(n^2)$</p>

<hr />

<h3 id="selection-sort">选择排序 (Selection Sort)</h3>
<p>思想：在确定第 $i$ 个位置的数值时，从 $[i+1, n)$中选出数值最小的记录，并和第 $i$ 个记录交换。</p>

<p>复杂度：时间复杂度为 $O(n^2)$，尽管与冒泡排序相同，但是性能上优于冒泡排序。</p>

<hr />

<h3 id="insertion-sort">插入排序 (Insertion Sort)</h3>
<p>思想：将一个记录插入到已经排好序的有序表中，从而得到新的、录数增加 1 的有序表。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/2016-07-06-sorting-insertion-sort.png' width='512' height='256' title=''><span class='caption-text'></span></span></p>

<p>复杂度：时间复杂度为 $O(n^2)$，但是性能上优于冒泡排序和选择排序。</p>

<hr />

<h3 id="shell-sort">希尔排序 (Shell Sort)</h3>
<p>插入排序的效率在某些时候很高，比如，记录本身就是基本有序的。还有就是记录数比较少时，直接插入的优势比较明显。希尔排序是插入排序的改进。</p>

<p>思想：分割待排序的记录，减少待排序记录的个数。将相距某个“增量”的记录组成一个子序列（实现跳跃式移动），在子序列内分别进行插入排序，使得结果基本有序。最后对整个序列插入排序。</p>

<p>复杂度：时间复杂度为 $O(n^{3/2})$。</p>

<p>注：由于记录是跳跃式的移动，希尔排序不是稳定的排序算法。</p>

<hr />

<h3 id="heap-sort">堆排序 (Heap Sort)</h3>
<p>如果可以做到在每次选择到最小记录的同时，并根据比较结果对其记录做出相应的调整，那样排序的总体效率会很高。堆排序就是对选择排序的改进。</p>

<p>思想：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根结点。将它移走，然后将剩余 n-1 个记录重新构造成一个大顶堆，这样就能得到 n 个元素中次大的值。如此反复得到一个有序序列。</p>

<p>复杂度：堆初始化的时间复杂度是 $O(n)$，重建堆的时间复杂度为 $O(nlogn)$。堆排序堆原始序列的状态不敏感，所以它的最好，平均，最坏时间复杂度是 $O(nlogn)$。</p>

<p>注：由于记录的比较和交换是跳跃式进行的，堆排序不是稳定的排序算法。</p>

<hr />

<h3 id="merge-sort">归并排序 (Merge Sort)</h3>
<p>思想：将待排序序列看做是 n 个有序的子序列，每个子序列的长度为 1，然互两两归并得到 [n/2] 个长度为 2 或 1 的有序子序列，再两两归并。如此重复直到长度为 n 的有序序列为止。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/2016-07-06-sorting-merge-sort.png' width='512' height='256' title=''><span class='caption-text'></span></span></p>

<p>复杂度：最好，平均，最坏时间复杂度都是 $O(nlogn)$。由于在 Merge 的过程中需要与记录序列同样数量的存储空间存放结果，所以空间复杂度是 $O(n)$。</p>

<p>注：归并排序需要两两比较，不存在跳跃，因此归并排序是一种稳定的排序算法。</p>

<hr />

<h3 id="quick-sort">快速排序 (Quick Sort)</h3>
<p>思想：通过一趟排序将记录分割成独立的两部分，其中一部分记录的数值比另一部分记录的数值小。然后分别对这两部分继续排序，以达到整个序列有序的目的。</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/2016-07-06-sorting-quick-sort.png' width='512' height='256' title=''><span class='caption-text'></span></span></p>

<p>复杂度：最有情况下，Partition 每次划分的很均匀，时间复杂度为 $O(nlogn)$。最坏情况下，待排序列为正序或者反序，时间复杂度为 $O(n^2)$。平均情况下，时间复杂度可证明为 $O(nlogn)$。</p>

<p>注：由于记录的比较和交换是跳跃式进行的，快速排序不是稳定的排序算法。</p>

<hr />

<h3 id="bucket-sort">桶排序 (Bucket Sort)</h3>
<p>之前介绍的排序算法都是基于两个数值之间的比较来确定位置的先后关系。桶排序则不是，所以它比快排还快，能够在  $O(n)$ 的时间内完成。但是缺点是非常耗费空间，如果序列中最大数为 m，那么需要 m 个桶。</p>

<p>思想：把记录 a[i] 放入第 a[i] 个桶中。</p>

<p>[6 2 4 1 5 9]           待排数组</p>

<p>[0 1 2 0 4 5 6 0 0 9]   空桶</p>

<p>[0 1 2 3 4 5 6 7 8 9]   桶编号(实际不存在)</p>

<p><span class='caption-wrapper'><img class='caption' src='/images/2016-07-06-sorting-bucket-sort.png' width='512' height='256' title=''><span class='caption-text'></span></span></p>

<p>复杂度：时间复杂度$O(n)$</p>

<p>注：桶排序是稳定的</p>

<p><code>cpp
int[] bucket_sort(int[] unsorted, int maxNumber = 99)
{
   int[] sorted = new int[maxNumber + 1];
   for (int i = 0; i &lt; unsorted.Length; i++)
	   sorted[unsorted[i]] = unsorted[i];
   return sorted;
</code></p>

<hr />

<h3 id="counting-sort">计数排序 (Counting Sort)</h3>
<p>思想：计数排序假设 n 个输入元素中的每一个都是介于 [0, k] 的整数，此处 k 为某个整数。计数排序顾名思义离不开计数，我们要计的是输入元素中相同元素出现的次数。对每一个输入元素 x，确定小于 x 的元素的个数，那样排序之后，x 在最终输出数组中的位置就可以确定了。</p>

<p>假定输入数组为 A[1..n]，他们的值均位于 0~k 之间，输出排序之后的数组为 B[1..n]，以及临时存储数组 C[0..k]。计数排序的伪代码如下：</p>

<p><code>cpp
memset(C,sizeof(C),0);  //C 数组置零  
for i=1 to n do  
    C[A[i]]++;          //统计输入数组中相同元素的个数  
for i=2 to k do  
    C[i] = C[i]+C[i-1]; //C[i]表示输入数组中小于或者等于 i 的元素个数  
for i=n downto 1 do  
    B[C[A[i]]] = A[i];  //把每一个 A[i]放到输出数组中相应位置上  
    C[A[i]]--;          //如果有几个相同元素时,当然不能放在同一个位置了。
</code></p>

<p>计数排序特点：
1.  提前必须是已知待排序的关键字为整型且范围已知。
2.  时间复杂度为 O(n+k)，不是基于比较的排序算法，因此效率非常之高。
3.  稳定性好，这个是计数排序非常重要的特性，可以用在后面介绍的基数排序中。
4.  但需要一些辅助数组，如 C[0..k]，因此待排序的关键字范围 0~k 不宜过大。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Topological Sorting]]></title>
    <link href="http://shengmingzhiqing.com/blog/topological-sorting.html/"/>
    <updated>2016-07-06T20:37:06+08:00</updated>
    <id>http://shengmingzhiqing.com/blog/topological-sorting</id>
    <content type="html"><![CDATA[<h3 id="section">定义</h3>
<p>在一个表示工程的有向图中，用定点表示活动，用弧表示活动之间的优先关系，这样的有向图为顶点表示活动的网，称为 AOV 网(Activity on Vertex Network)。</p>

<!--more-->

<p>设 G=(V, E) 是一个具有 n 个顶点的有向图， 若顶点 $v_i$ 到 $v_j$ 有一条路径，则在顶点序列中顶点 $v_i$ 必须在顶点 $v_j$  之前，称这样的序列为一个拓扑排序。</p>

<h3 id="section-1">算法</h3>
<p>从 AOV 网中选择一个入度为 0 的顶点输出，然后删除次顶点，并删除以此顶点为起点的弧，继续重复此步骤，直到网络输出全部顶点或者 AOV 网中不存在入度为 0 的顶点为止。</p>

<h3 id="section-2">应用</h3>
<p>某大型项目由 n 个组件 N1, N2……Nn 构成，每个组件都可以独立编译，但是某些组件的编译依赖于其它组件（即某些组件只能在其它组件编译完成后才能编译），设计算法给出统计过程。</p>

<p>思路：拓扑排序算法</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Back Tracking]]></title>
    <link href="http://shengmingzhiqing.com/blog/back-tracking.html/"/>
    <updated>2016-07-06T20:34:10+08:00</updated>
    <id>http://shengmingzhiqing.com/blog/back-tracking</id>
    <content type="html"><![CDATA[<h4 id="section">1. 概念</h4>
<p>　　回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。
　　许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。</p>

<!--more-->

<h4 id="section-1">2.基本思想</h4>
<p>　　在包含问题的所有解的解空间树中，按照深度优先搜索的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯（其实回溯法就是对隐式的深度优先搜索算法）。</p>

<h4 id="section-2">3. 解题步骤</h4>
<ol>
  <li>针对所给问题，确定问题的解空间，问题的解空间应至少包含问题的一个（最优）解。</li>
  <li>确定结点的扩展搜索规则</li>
  <li>以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。</li>
</ol>

<h4 id="section-3">4. 算法框架</h4>
<ol>
  <li>
    <p>问题框架：
设问题的解是一个 n 维向量 (a1,a2,………,an)，约束条件是 ai(i=1,2,3,…..,n) 之间满足某种条件，记为 f(ai)。</p>
  </li>
  <li>
    <p>递归的算法框架：
回溯法是对解空间的深度优先搜索，在一般情况下使用递归函数来实现回溯法比较简单，其中 i 为搜索的深度，框架如下：</p>
  </li>
</ol>

<p><code>cpp
int a[n];
try(int i)
{
  if(i&gt;n)
    输出结果; 
  else
  {
    for(j = 下界; j &lt;= 上界; j=j+1)  // 枚举 i 所有可能的路径
    {
      if(fun(j))     // 满足限界函数和约束条件
      {
        a[i] = j;
        ...          // 其他操作
        try(i+1);
        回溯前的清理工作（如 a[i]置空值等）;
      }
    }
  }
} 
</code></p>
]]></content>
  </entry>
  
</feed>
